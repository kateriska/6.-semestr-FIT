Architektury Výpočetních Systémů (AVS 2020)
Projekt č. 2 (PMC)
Login: xlogin00

Úloha 1: Paralelizace původního řešení
===============================================================================

1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?

Vhodnější je paralizovat smyčku ve funkci unsigned LoopMeshBuilder::marchCubes(const ParametricScalarField &field). Neefektivní paralizaci druhé smyčky (která by měla za následek velké zpomalení programu) způsobuje skutečnost, že režie vynaložená na danou paralelizaci je příliš vysoká a celý výpočet se tedy hodně zpomalí. 

2) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? 
   Jaký vliv má velikost "chunk" při dynamickém plánování (8, 16, 32, 64)?

Využila jsem guided plánování, které má nižší synchronizační režii jak např. dynamic a mělo by se jednat o nejefektivnější způsob plánování.

Hodnoty pro bun_zipper_res4.obj:
+-----------------+------------+-------------------+
| Scheduling Type | Chunk Size | Elapsed Time [ms] |
+-----------------+------------+-------------------+
| guided          |            | 197               |
+-----------------+------------+-------------------+
| dynamic         | 8          | 435               |
+-----------------+------------+-------------------+
| dynamic         | 16         | 490               |
+-----------------+------------+-------------------+
| dynamic         | 32         | 201               |
+-----------------+------------+-------------------+
| dynamic         | 64         | 306               |
+-----------------+------------+-------------------+

Dle měření má dynamické plánování obecně větší čas výpočtu, jak plánování guided. Čím je chunk_size větší, tím je menší synchronizační režie, ale hrubší vyvážení zátěže.


3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?
Bylo nutné vytvořit kritickou sekci #pragma omp critical, kdy daný úsek může vždy v daném čase vykonávat pouze jedno vlákno. 


Úloha 2: Paralelní průchod stromem
===============================================================================

1) Stručně popište použití OpenMP tasků ve vašem řešení.
Při volání funkce unsigned TreeMeshBuilder::octaTree(const ParametricScalarField &field, unsigned mGridSize, const Vec3_t<float> &cubeOffset) bude využito paralelismu, vytvoří se tedy tým vláken (#pragma omp parallel). Dále bude blok vykonáván pouze jednou jedním vláknem z daného týmu (#pragma omp single nowait).

Při každé tvorbě nového potomka je vytvořen nový task. Pro aktualizaci finálního počtu bylo zapotřebí využití #pragma omp atomic, aby se daná proměnná pro finální počet trojúhelníků inkrementovala atomicky a zápis vláken do této proměnné je tedy kontrolován. Na konci je poté potřeba počkat na všechny generované tasky (#pragma omp taskwait), tedy i jejich následníky. 

Ukládání trojúhelníků z několika vláken je opět jako v Úloze 1 zajištěno pomocí #pragma omp critical.

2) Jakým způsobem jste realizovali sesbírání celkového počtu trojúhelníků?
Na začátku je nutné ověřit podmínku, zda je možné aby jeho podprostorem procházel hledaný povrch (rovnice 6.3 v zadání). Ověřila jsem tedy danou nerovnici uvedenou v zadání. Na nejnižší úrovni se volá funkce buildCube, jinak se velikost mřížky rozdělí na polovinu (velikost mřížky předpokládáme dle zadání pouze o mocninách 2) a vytvoří se noví potomci, kdy pro každého z nich je vytvořen nový task. Rekurzivně se poté znovu volá funkce octaTree a v každé iteraci je spočítán daný počet, který se přičítá atomicky do proměnné count, která obsahuje finální počet všech trojúhelníků.

3) Jaký vliv má na vaše řešení tzv. "cut-off"? Je vhodné vytvářet nový 
   task pro každou krychli na nejnižší úrovni?

Hodnoty pro bun_zipper_res4.obj:
+---------------+-------------------+----------------+---------------------+
| Cut Off Value | Elapsed Time [ms] | File Size [KB] | Mesh Triangle Count |
+---------------+-------------------+----------------+---------------------+
| 0.2           | 244               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 0.5           | 211               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 0.8           | 206               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 1             | 35                | 5442           | 42476               |
+---------------+-------------------+----------------+---------------------+
| 1.5           | 36                | 5442           | 42476               |
+---------------+-------------------+----------------+---------------------+
| 2             | 14                | 694            | 5516                |
+---------------+-------------------+----------------+---------------------+

Vidíme, že nastavení cut-off na nižší hodnotu jak 1 má za následek velmi velké navýšení času výpočtu (ve srovnání s tím, když danou hodnotu cut-off nastavíme na 1). Na druhou stranu při hodnotě cut_off např. 2 pak nejsou vykreslené všechny trojúhelníky daného objektu. Není vhodné vytvářet nový task na nejnižší úrovni, protože na této úrovni pouze generujeme samotné polygony pro všechny krychle náležející do daného podprostoru.

4) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?
Pro tento problém bylo opět jak u Úlohy 1 využito #pragma omp critical, kdy daný úsek kódu je v daném čase vykonáván pouze jedním vláknem.


Úloha 3: Předvýpočet hodnot pole
===============================================================================

1) Dochází v případě tohoto řešení k omezení výkonu propustností paměti? 
   Došlo k nějakým změnám ve využití paměťového subsystému v porovnání 
   s úlohou 1?
   (Ověřte nástrojem Intel VTune na některé z větších mřížek -- např. 512)

2) V jaké situaci bude toto řešení nejvýhodnější (nejrychlejší)?


Úloha 4: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení (na základě grafů škálování).
Silné škálování:

Octree dokáže s více vlákny počítat za kratší čas jak referenční Loop řešení.

2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? (pokud takový případ existuje)

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?
