Architektury Výpočetních Systémů (AVS 2020)
Projekt č. 2 (PMC)
Login: xforto00

Úloha 1: Paralelizace původního řešení
===============================================================================

1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?

Vhodnější je paralizovat smyčku ve funkci unsigned LoopMeshBuilder::marchCubes(const ParametricScalarField &field). Neefektivní paralizaci druhé smyčky (která by měla za následek velké zpomalení programu) způsobuje skutečnost, že režie vynaložená na danou paralelizaci je příliš vysoká (nevyplatí se, protože výpočty ve smyčce jsou pravděpodobně moc jednoduché) a celý výpočet se tedy hodně zpomalí. 

2) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? 
   Jaký vliv má velikost "chunk" při dynamickém plánování (8, 16, 32, 64)?

Využila jsem guided plánování, které má nižší synchronizační režii jak např. dynamic a mělo by se jednat o nejefektivnější způsob plánování.

Hodnoty pro bun_zipper_res4.obj, default velikost mřížky:
+-----------------+------------+-------------------+
| Scheduling Type | Chunk Size | Elapsed Time [ms] |
+-----------------+------------+-------------------+
| guided          |            | 175               |
+-----------------+------------+-------------------+
| dynamic         | 8          | 229               |
+-----------------+------------+-------------------+
| dynamic         | 16         | 238               |
+-----------------+------------+-------------------+
| dynamic         | 32         | 258               |
+-----------------+------------+-------------------+
| dynamic         | 64         | 298               |
+-----------------+------------+-------------------+

Dle měření má dynamické plánování obecně spíše větší čas výpočtu jak plánování guided. Čím je chunk_size větší, tím je menší synchronizační režie, ale hrubší vyvážení zátěže. A jak vidíme v naměřených hodnotách, doba výpočtu se spíše zvyšuje (závisí však často na aktuálním běhu programu).

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?
Bylo nutné vytvořit kritickou sekci #pragma omp critical, kdy daný úsek může vždy v daném čase vykonávat pouze jedno vlákno. 


Úloha 2: Paralelní průchod stromem
===============================================================================

1) Stručně popište použití OpenMP tasků ve vašem řešení.
Při volání funkce unsigned TreeMeshBuilder::octaTree(const ParametricScalarField &field, unsigned mGridSize, const Vec3_t<float> &cubeOffset) bude využito paralelismu, vytvoří se tedy tým vláken (#pragma omp parallel). Dále bude blok vykonáván pouze jednou jedním vláknem z daného týmu (#pragma omp single).

Při každé tvorbě nového potomka je vytvořen nový task (#pragma omp task). Pro aktualizaci finálního počtu bylo zapotřebí využití #pragma omp atomic, aby se daná proměnná pro finální počet trojúhelníků inkrementovala atomicky a zápis vláken do této proměnné je tedy kontrolován, tato proměnná je sdílená. Na konci je poté potřeba počkat na všechny generované tasky (#pragma omp taskwait), tedy i jejich následníky.

Ukládání trojúhelníků z několika vláken je opět jako v Úloze 1 zajištěno pomocí #pragma omp critical.

2) Jakým způsobem jste realizovali sesbírání celkového počtu trojúhelníků?
Na začátku je nutné ověřit podmínku, zda je možné aby jeho podprostorem procházel hledaný povrch (nerovnice 6.3 v zadání). Ověřila jsem tedy danou nerovnici. Na nejnižší úrovni se volá funkce buildCube, jinak se velikost mřížky rozdělí na polovinu (velikost mřížky předpokládáme dle zadání pouze o mocninách 2) a vytvoří se noví potomci, kdy pro každého z nich je vytvořen nový task. Rekurzivně se poté znovu volá funkce octaTree a v každé iteraci je spočítán daný počet, který se přičítá atomicky do sdílené proměnné count, která obsahuje finální počet všech trojúhelníků.

3) Jaký vliv má na vaše řešení tzv. "cut-off"? Je vhodné vytvářet nový 
   task pro každou krychli na nejnižší úrovni?

Hodnoty pro bun_zipper_res4.obj, default velikost mřížky:
+---------------+-------------------+----------------+---------------------+
| Cut Off Value | Elapsed Time [ms] | File Size [KB] | Mesh Triangle Count |
+---------------+-------------------+----------------+---------------------+
| 0.2           | 213               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 0.5           | 240               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 0.8           | 246               | 21696          | 168168              |
+---------------+-------------------+----------------+---------------------+
| 1             | 38                | 5442           | 42476               |
+---------------+-------------------+----------------+---------------------+
| 1.5           | 42                | 5442           | 42476               |
+---------------+-------------------+----------------+---------------------+
| 2             | 8                 | 694            | 5516                |
+---------------+-------------------+----------------+---------------------+

Vidíme, že nastavení cut-off na nižší hodnotu jak 1 má za následek velmi velké navýšení času výpočtu (ve srovnání s tím, když danou hodnotu cut-off nastavíme na 1). Na druhou stranu při hodnotě cut-off např. 2 i když se může zdát, že čas výpočtu je rychlejší, tak je zde jeden zásadní problém - nejsou vykreslené všechny trojúhelníky daného objektu. Není vhodné vytvářet nový task na nejnižší úrovni, protože na této úrovni pouze generujeme samotné polygony pro všechny krychle náležející do daného podprostoru.

4) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?
Pro tento problém bylo opět jak u Úlohy 1 využito #pragma omp critical, kdy daný úsek kódu je v daném čase vykonáván pouze jedním vláknem.


Úloha 3: Předvýpočet hodnot pole
===============================================================================

1) Dochází v případě tohoto řešení k omezení výkonu propustností paměti? 
   Došlo k nějakým změnám ve využití paměťového subsystému v porovnání 
   s úlohou 1?
   (Ověřte nástrojem Intel VTune na některé z větších mřížek -- např. 512)

Byla využita Memory Access analýza s použitím nástroje VTune pro velikost mřížky 512.

Hodnoty pro bun_zipper_res4.obj, velikost mřížky 512:
Loop verze: Memory Bound celkové: 7.8 %
	    Funkce evaluateFieldAt: 0.1 %
	    Funkce marchCubes: 34 %
Cached verze: Memory Bound celkové: 11.2 %, VTune již varuje před vysokou hodnotou
	      Funkce evaluateFieldAt: 25 %
	      Funkce marchCubes: 2.9 %

Dle výsledků vidíme, že dochází k vyššímu omezení výkonu propustnosti pro funkci evaluateFieldAt pro Cached verzi. Jedná se o funkci, kde právě přistupujeme k daným hodnotám 1D pole, které obsahuje předpočítané odmocniny. Pokud implementaci této funkce srovnáme s její implementací v Loop verzi, kdy se nevyužívá žádné pole předvypočítaných hodnot, ale daná hodnota se zde musí vypočítat, tak zjistíme, že v Loop verzi v příslušné funkci byla hodnota Memory Bound velmi nízká (0.1 %) ve srovnání s hodnotou 25 %, které funkce dosáhla v Cached variantě.

Dále bylo zjištěno a porovnáno celkové LLC Miss Count:
Hodnoty pro bun_zipper_res4.obj, velikost mřížky 512:
Loop verze: 322 009 660
Cached verze: 735 022 050

Jak vidíme, v případě Cached varianty došlo ke skoro 2.3 násobnému navýšení hodnoty LLC Miss Count.
U varianty Cached tedy častějí dochází k výpadkům v last-level cache a více požadavků se musí obsluhovat DRAM, která má však značnou latenci.  

2) V jaké situaci bude toto řešení nejvýhodnější (nejrychlejší)?
Dle grafu škálování na základě velikosti mřížky můžeme vidět, že Cached verze je nejvhodnější při nízké velikosti mřížky, protože má pro tento případ nejnižší dobu výpočtu ve srovnání s Octree a Loop.


Úloha 4: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení (na základě grafů škálování).

Z grafu škálování na základě velikosti mřížky vyplývá, že obecně nejméně efektivním řešením je Loop.
Octree je méně efektivní než Cached a Loop při malé velikosti mřížky, ale s rostoucí velikostí mřížky dosahuje lepších výsledků. Při malé velikosti mřížky je nejvýhodnější využít variantu Cached.

Z grafu slabého škálování můžeme zjistit následující: Cached verze se pro jakékoliv velikosti vstupu pro vlákno pohybuje v úzkém časovém intervalu doby výpočtu (ve srovnání s Octree a Loop). Octree verze je velmi výhodná ve srovnání s ostatními variantami zvláště pro menší velikost vstupu pro vlákno. Loop verze je nejvíce srovnatelná s Cached pro malé velikosti vstupu pro vlákno. U vyšších velikostí vstupu pro vlákno (např. 160) už je podstatně horší, co se týče doby výpočtu.

Z grafu silného škálování vyplývá následující: Pro Cached verzi leží čas pro výpočet v nejužším časovém intervalu výpočtu pro všechny velikosti vstupu (ve srovnání se dvěma zbývajícími metodami). Octree pracuje nejlépe pro malé velikosti vstupů, ovšem pro vyšší velikosti vstupu by už bylo výhodnější využít Cached. Loop se poté pro malé velikosti vstupu chová podobně jako Cached, ale pro vyšší velikosti vstupu se už chová hůře a doba výpočtu je vyšší.

2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? (pokud takový případ existuje)

Co se týče závislosti na velikosti mřížky, nejedná se pro Loop v žádné části příslušného grafu škálování na základě velikosti mřížky opravdu o velmi neefektivní řešení. V tomto grafu vidíme, že rozdíly mezi všemi třemi variantami nejsou tolik markantní, co se týče doby výpočtu. 

Kde už však můžeme pozorovat jistou vyšší neefektivitu, minimálně ve srovnání s variantou Cached je případ, kdy máme velkou velikost vstupu a nízký počet vláken.

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?

Octree je nejefektivnějším ze všech tří variant, pokud počítáme s nižší velikosti vstupu pro vlákno. Pokud máme např. velikost vstupu pro vlákno 80, tak už je doba výpočtu srovnatelná s Cached a pro nejvyšší měřenou velikost vstupu pro vlákno 160 je již efektivnějším Cached.

Co se týče však porovnání Octree s Loop, tak tam je Octree opravdu stále efektivnějším. Obecně zde výpočet trvá kratší dobu, ať už vezmeme jakýkoliv počet vláken i velikost vstupu pro dané vlákno.

